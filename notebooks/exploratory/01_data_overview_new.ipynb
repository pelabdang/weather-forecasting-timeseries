{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6a32e5f",
   "metadata": {},
   "source": [
    "# Weather Forecasting Time Series - Data Overview\n",
    "\n",
    "## Project Overview\n",
    "This notebook provides an initial overview of the weather dataset for time series forecasting. We'll examine the basic structure, quality, and characteristics of the data to understand what we're working with.\n",
    "\n",
    "## Objectives\n",
    "1. **Data Loading & Inspection**: Load and understand the basic structure of our weather dataset\n",
    "2. **Data Quality Assessment**: Identify missing values, data types, and potential issues\n",
    "3. **Basic Statistics**: Compute descriptive statistics and understand data distributions\n",
    "4. **Data Preparation**: Prepare the dataset for deeper analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeaa6c5",
   "metadata": {},
   "source": [
    "## 1. Library Imports and Setup\n",
    "\n",
    "Import all necessary libraries for data loading, basic analysis, and our custom utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2c37ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), '..'))\n",
    "import src.data.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0ed325",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Initial Inspection\n",
    "\n",
    "Load the weather dataset and column descriptions to understand the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7edb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../data/raw/'\n",
    "\n",
    "raw = utils._load_data(path, 'weather_data.csv')\n",
    "cols_description = utils._load_data(path, 'column_descriptions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e99e25",
   "metadata": {},
   "source": [
    "### 2.1 Dataset Column Descriptions\n",
    "\n",
    "Understanding what each column represents in our weather dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4333ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)\n",
    "display(cols_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf6d69c",
   "metadata": {},
   "source": [
    "### 2.2 Data Preparation and Initial View\n",
    "\n",
    "Convert date column to datetime format and set as index for time series analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b388cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = utils._prepare_data(raw, 'date')\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e9b0b4",
   "metadata": {},
   "source": [
    "### 2.3 Basic Dataset Information\n",
    "\n",
    "Get an overview of the dataset dimensions, column types, and data quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6998d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_info = utils._basic_data_info(raw)\n",
    "print(f\"Dataset Shape: {basic_info['shape']}\")\n",
    "print(f\"Number of Columns: {len(basic_info['columns'])}\")\n",
    "print(f\"Number of Missing Values: {sum(basic_info['missing_values'].values())}\")\n",
    "print(f\"Memory Usage: {basic_info['memory_usage'] / (1024**2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbde0b3",
   "metadata": {},
   "source": [
    "### 2.4 Data Types and Missing Values\n",
    "\n",
    "Detailed view of column data types and missing value patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3101b148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary DataFrame\n",
    "data_summary = pd.DataFrame({\n",
    "    'Column': basic_info['columns'],\n",
    "    'Data_Type': [basic_info['dtypes'][col] for col in basic_info['columns']],\n",
    "    'Missing_Values': [basic_info['missing_values'][col] for col in basic_info['columns']],\n",
    "    'Missing_Percentage': [basic_info['missing_values'][col] / basic_info['shape'][0] * 100 for col in basic_info['columns']]\n",
    "})\n",
    "\n",
    "display(data_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b9e5d0",
   "metadata": {},
   "source": [
    "## 3. Basic Statistical Analysis\n",
    "\n",
    "Generate descriptive statistics for all numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e4f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe, correlations = utils._basic_statistics(raw)\n",
    "display(describe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627a588a",
   "metadata": {},
   "source": [
    "### 3.1 Time Range Analysis\n",
    "\n",
    "Understand the temporal coverage of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c4b44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset time range: {raw.index.min()} to {raw.index.max()}\")\n",
    "print(f\"Total time span: {raw.index.max() - raw.index.min()}\")\n",
    "print(f\"Number of unique years: {raw.index.year.nunique()}\")\n",
    "print(f\"Years covered: {sorted(raw.index.year.unique())}\")\n",
    "print(f\"Average measurements per day: {len(raw) / raw.index.date.nunique():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0609ff",
   "metadata": {},
   "source": [
    "### 3.2 Data Completeness by Year\n",
    "\n",
    "Check if we have complete data for each year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd84e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count observations per year\n",
    "yearly_counts = raw.groupby(raw.index.year).size()\n",
    "print(\"Observations per year:\")\n",
    "for year, count in yearly_counts.items():\n",
    "    expected_hours = 366 * 24 if year % 4 == 0 else 365 * 24  # Account for leap years\n",
    "    completeness = (count / expected_hours) * 100\n",
    "    print(f\"{year}: {count:,} observations ({completeness:.1f}% complete)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f6da12",
   "metadata": {},
   "source": [
    "## 4. Summary and Next Steps\n",
    "\n",
    "### Key Findings from Data Overview:\n",
    "\n",
    "**Data Quality:**\n",
    "- Dataset contains comprehensive weather measurements\n",
    "- Hourly measurements across multiple years\n",
    "- Minimal missing values identified\n",
    "\n",
    "**Dataset Characteristics:**\n",
    "- Multiple weather variables including temperature, humidity, pressure, wind, and solar radiation\n",
    "- Time series format suitable for forecasting applications\n",
    "- Good temporal coverage for model training\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "The data appears to be in good condition for analysis. The next notebook will focus on:\n",
    "1. **Detailed Exploratory Data Analysis**: Deep dive into patterns and relationships\n",
    "2. **Feature Engineering**: Create time-based and derived features\n",
    "3. **Pattern Analysis**: Visualize temporal patterns and correlations\n",
    "4. **Data Preparation**: Prepare features for modeling\n",
    "\n",
    "---\n",
    "\n",
    "*This completes the initial data overview. Proceed to `02_data_analysis.ipynb` for detailed exploratory analysis.*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
